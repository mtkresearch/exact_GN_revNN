Setup:
  Data:
    batch_size: 1024
    batch_size_test: 512
    name: cifar
    path: /proj//data
    num_classes: 10
    subset: 1024
    augmentations:
      - name: randomresizecrop
        args:
          size: [32,32]
          scale: [0.08, 1.0]
          ratio: [0.75, 1.33]
    add_random: false
    random_proj: false

  Experiment:
    description: Dense
    reversible: true
    train_ggn: false
    device: true
    seed: 44
    version: 1.0

  Model:
    feature_dim: 3072
    hidden_dim: 8000
    output_dim: 10
    bias: true
    num_layers: 12
    layer_norm: false
    non_linearity: true
    inv_method: default
    inv_method_args:
      rtol: 1.0e-2
      atol: 1.0e-5

Runtime:
  Train:
    Task:
      name: classification
    args:
      num_epochs: 100
      save_checkpoint_every: 1
      steps_for_printing: 1
      log_test: true
      log_full_train: False
    loss_function:
      args:
        use_identity: true
      name: cross_entropy
    optimizer:
      args:
        lr: 0.01
        weight_decay: 0.00
      name: sgd
    scheduler:
      # name: step
    checkpoint_path: null

Output:
  Results:
    output_dir: /proj///logs/results_cifar_FullBatch
    weight_root_dir: /proj///weights_FullBatch
    format_strs: ["log", "json", "csv", "tensorboard"]
